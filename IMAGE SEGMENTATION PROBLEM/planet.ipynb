{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the required libraries\n\nCudnn benchmark helps boost the training speed when inputs of similar sizes are used"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from fastai.script import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.distributed import *\nfrom fastprogress import fastprogress\nfrom torchvision.models import *\nfrom fastai.vision.models.xresnet import *\nfrom fastai.vision.models.xresnet2 import *\ntorch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating directory to save model weights later on"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\n!mkdir ../modeldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/planet-understanding-the-amazon-from-space/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/planet-understanding-the-amazon-from-space')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path.ls()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a MultiClass Classification Problem as each data has multiple class labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(path/'train_v2.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading data using Fastai Dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(path, size, bs, workers=None):\n    if workers is None: workers = min(8, num_cpus())\n    tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n    return (ImageList.from_csv(path, 'train_v2.csv', folder='train-jpg', suffix='.jpg')\n            .split_by_rand_pct(0.2)\n            .label_from_df(label_delim=' ')\n            .add_test_folder('test-jpg-v2')\n            .transform(tfms, size=size)\n            .databunch(bs=bs, num_workers=workers)\n            .normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = get_data(path, 128, 64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(12,9))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use accuracy_thresh instead of accuracy. accuracy_thresh selects the classes that are above a certain threshold (0.5 by default) and compares them to the ground truth.\n\nAs for Fbeta, it's the metric that was used by Kaggle on this competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_02 = partial(accuracy_thresh, thresh=0.2)\nf_score = partial(fbeta, thresh=0.2)\nmetrics = [acc_02, f_score]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arch = resnet50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, arch, wd=1e-2,\n             metrics=metrics,\n             bn_wd=False, true_wd=True,\n             #loss_func = LabelSmoothingCrossEntropy()\n            )\nm = globals()['xresnet50']\nlearn = Learner(data, m(c_out=data.c), wd=1e-2,\n        metrics=metrics,\n        bn_wd=False, true_wd=True,\n    )\nlearn.model_dir = \"../modeldata\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use the LR Finder to pick a good learning rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we fit the head of our network"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, slice(0.02))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And fine-tune the whole model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('save1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we increase the image size to allow the model to learn more details from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.data = get_data(path, 256, 64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"learn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, 1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('save2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test Time augmentations allow us to perform data augmentation during testing phase and then give an average prediction score for the classes which would be better than using the original image in most of the cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds, _ = learn.get_preds(ds_type=DatasetType.Test)\npreds, _ = learn.TTA(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While predicting labels we set the threshold as 0.2 which was earlier used for training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh = 0.2\nlabelled_preds = [' '.join([learn.data.classes[i] for i,p in enumerate(pred) if p > thresh]) for pred in preds]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelled_preds[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = [f.name[:-4] for f in learn.data.test_ds.items]\ndf = pd.DataFrame({'image_name':fnames, 'tags':labelled_preds}, columns=['image_name', 'tags'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks('.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}